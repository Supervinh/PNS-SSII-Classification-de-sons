{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification des sons avec différentes valeurs de k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partie des imports\n",
    "################################################################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import librosa\n",
    "import librosa.display\n",
    "import sounddevice as sd\n",
    "import IPython.display as ipd\n",
    "import glob\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print(*args, **kwargs):\n",
    "    '''méthode de print conditionnée par la valeur de la variable verbose'''\n",
    "    global verbose\n",
    "    try:\n",
    "        if verbose:\n",
    "            print(*args, *kwargs)\n",
    "    except NameError:\n",
    "        print(*args, *kwargs)\n",
    "        \n",
    "        \n",
    "def build_bof(k, lesLabels, dimSons):\n",
    "    '''méthode pour construire le Bag Of Features d'un échantillon de sons'''\n",
    "    bofs = np.empty(shape = (0, k), dtype = int) # tableau des BoF\n",
    "    i = 0 # indice pour le parcours de MFCC\n",
    "\n",
    "    for nbS in dimSons: # Parcours des sons\n",
    "        tmpBof = np.array([0]*k) # initialisation du BOF pour le son courant\n",
    "        j = 0\n",
    "        while j < nbS: # pour chaque MFCC de ce son\n",
    "            tmpBof[lesLabels[i]] += 1\n",
    "            j+=1\n",
    "            i+=1\n",
    "        tmpBof = tmpBof/nbS # transformation en pourcentage\n",
    "        copyBof = tmpBof.copy()\n",
    "        bofs = np.append(bofs, [copyBof], 0)\n",
    "    \n",
    "    return bofs\n",
    "\n",
    "\n",
    "def build_MFCC(listSons, lesMfcc, dimSons, nb = 20):\n",
    "    '''méthode pour construite le tableau des MFCC d'un échantillon de sons'''\n",
    "    for s in listSons[:nb]: # on prends les nb premiers sons de la liste 1\n",
    "        sig, rate = librosa.load(s)\n",
    "        mfcc_feat = librosa.feature.mfcc(sig,rate,n_mfcc=13) # on calcule les MFCC du son\n",
    "\n",
    "        Print('file: ', '/'.join(s.split('\\\\')[-2:]), '\\tMFCC:', mfcc_feat.shape, '\\tlen:', len(sig))\n",
    "\n",
    "        lesMfcc = np.append(lesMfcc, mfcc_feat.transpose(), axis = 0) # on ajoute les MFCC du son à notre array\n",
    "        dimSons.append(mfcc_feat.shape[1]) # et on \"déclare\" le nombre de MFCC du son\n",
    "    return lesMfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score pour k = 2: 0.5957446808510639\n",
      "test score pour k = 2: 0.6666666666666666\n",
      "train score pour k = 3: 0.6046511627906976\n",
      "test score pour k = 3: 0.8181818181818182\n",
      "train score pour k = 4: 0.6666666666666667\n",
      "test score pour k = 4: 0.6956521739130435\n",
      "train score pour k = 5: 0.8372093023255814\n",
      "test score pour k = 5: 0.75\n",
      "train score pour k = 6: 0.7804878048780488\n",
      "test score pour k = 6: 0.7826086956521738\n",
      "train score pour k = 7: 0.761904761904762\n",
      "test score pour k = 7: 0.7826086956521738\n",
      "train score pour k = 8: 0.8571428571428572\n",
      "test score pour k = 8: 0.8571428571428572\n",
      "train score pour k = 9: 0.7906976744186046\n",
      "test score pour k = 9: 0.8181818181818182\n",
      "train score pour k = 10: 0.7906976744186046\n",
      "test score pour k = 10: 0.7826086956521738\n",
      "train score pour k = 11: 0.8636363636363635\n",
      "test score pour k = 11: 0.9090909090909091\n",
      "train score pour k = 12: 0.8571428571428572\n",
      "test score pour k = 12: 0.7272727272727272\n",
      "train score pour k = 13: 0.8837209302325583\n",
      "test score pour k = 13: 0.8571428571428572\n",
      "train score pour k = 14: 0.85\n",
      "test score pour k = 14: 0.6956521739130435\n",
      "train score pour k = 15: 0.8292682926829269\n",
      "test score pour k = 15: 0.6363636363636365\n",
      "train score pour k = 16: 0.8095238095238095\n",
      "test score pour k = 16: 0.6666666666666666\n",
      "train score pour k = 17: 0.7906976744186046\n",
      "test score pour k = 17: 0.6956521739130435\n",
      "train score pour k = 18: 0.8205128205128205\n",
      "test score pour k = 18: 0.6363636363636365\n",
      "train score pour k = 19: 0.75\n",
      "test score pour k = 19: 0.6363636363636365\n",
      "train score pour k = 20: 0.8372093023255814\n",
      "test score pour k = 20: 0.6\n",
      "train score pour k = 21: 0.75\n",
      "test score pour k = 21: 0.6956521739130435\n",
      "train score pour k = 22: 0.8181818181818182\n",
      "test score pour k = 22: 0.6363636363636365\n",
      "train score pour k = 23: 0.8571428571428572\n",
      "test score pour k = 23: 0.6956521739130435\n",
      "train score pour k = 24: 0.8636363636363635\n",
      "test score pour k = 24: 0.7272727272727272\n",
      "train score pour k = 25: 0.8372093023255814\n",
      "test score pour k = 25: 0.6363636363636365\n",
      "train score pour k = 26: 0.8444444444444444\n",
      "test score pour k = 26: 0.6666666666666666\n",
      "train score pour k = 27: 0.7804878048780488\n",
      "test score pour k = 27: 0.6666666666666666\n",
      "train score pour k = 28: 0.9047619047619048\n",
      "test score pour k = 28: 0.6666666666666666\n",
      "train score pour k = 29: 0.7441860465116279\n",
      "test score pour k = 29: 0.761904761904762\n",
      "train score pour k = 30: 0.8372093023255814\n",
      "test score pour k = 30: 0.7368421052631577\n",
      "train score pour k = 31: 0.7906976744186046\n",
      "test score pour k = 31: 0.761904761904762\n",
      "train score pour k = 32: 0.8636363636363635\n",
      "test score pour k = 32: 0.8000000000000002\n",
      "train score pour k = 33: 0.8571428571428572\n",
      "test score pour k = 33: 0.588235294117647\n",
      "train score pour k = 34: 0.8095238095238095\n",
      "test score pour k = 34: 0.8000000000000002\n",
      "train score pour k = 35: 0.7894736842105262\n",
      "test score pour k = 35: 0.631578947368421\n",
      "train score pour k = 36: 0.8444444444444444\n",
      "test score pour k = 36: 0.8000000000000002\n",
      "train score pour k = 37: 0.8000000000000002\n",
      "test score pour k = 37: 0.6666666666666666\n",
      "train score pour k = 38: 0.8000000000000002\n",
      "test score pour k = 38: 0.588235294117647\n",
      "train score pour k = 39: 0.8571428571428572\n",
      "test score pour k = 39: 0.7368421052631577\n",
      "train score pour k = 40: 0.8636363636363635\n",
      "test score pour k = 40: 0.7058823529411764\n",
      "train score pour k = 41: 0.8571428571428572\n",
      "test score pour k = 41: 0.6666666666666665\n",
      "train score pour k = 42: 0.7906976744186046\n",
      "test score pour k = 42: 0.7368421052631577\n",
      "train score pour k = 43: 0.7804878048780488\n",
      "test score pour k = 43: 0.5263157894736842\n",
      "train score pour k = 44: 0.8571428571428572\n",
      "test score pour k = 44: 0.8000000000000002\n",
      "train score pour k = 45: 0.7804878048780488\n",
      "test score pour k = 45: 0.47058823529411764\n",
      "train score pour k = 46: 0.8837209302325583\n",
      "test score pour k = 46: 0.7058823529411764\n",
      "train score pour k = 47: 0.7804878048780488\n",
      "test score pour k = 47: 0.7\n",
      "train score pour k = 48: 0.8571428571428572\n",
      "test score pour k = 48: 0.8000000000000002\n",
      "train score pour k = 49: 0.8780487804878048\n",
      "test score pour k = 49: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# partie d'initialisation des fichiers sons\n",
    "################################################################################################################\n",
    "\n",
    "basedir=\"./Sons/\"\n",
    "class1 = 'Gauche'\n",
    "class2 = 'Droite'\n",
    "\n",
    "listSons1 = glob.glob(basedir+class1+\"/*.wav\")\n",
    "listSons2 = glob.glob(basedir+class2+\"/*.wav\")\n",
    "\n",
    "Print(f'Classe 1: {len(listSons1)} sons.'.format())\n",
    "Print(f'Classe 2: {len(listSons2)} sons.'.format())\n",
    "\n",
    "\n",
    "# partie construction du vecteur de tous les MFCC\n",
    "################################################################################################################\n",
    "\n",
    "nb = 20 # nombre de sons dans l'échantillon\n",
    "lesMfcc = np.empty(shape = (0, 13), dtype = float) # tableau de tous les MFCC (de tous les sons)\n",
    "dimSons = []\n",
    "lesMfcc = build_MFCC(listSons1, lesMfcc, dimSons, nb)\n",
    "Print()\n",
    "lesMfcc = build_MFCC(listSons2, lesMfcc, dimSons, nb)\n",
    "Print('\\nNombre total de MFCC:', lesMfcc.shape)\n",
    "Print('Nombre de MFCC dans l\\'ordre des sons:', dimSons)\n",
    "\n",
    "\n",
    "nbTest=10\n",
    "lesMfccTest = np.empty(shape=(0, 13), dtype=float)\n",
    "dimSonsTest = []\n",
    "# on va prendre les nb derniers sons\n",
    "lesMfccTest = build_MFCC(listSons1[-nbTest:], lesMfccTest, dimSonsTest, nbTest)\n",
    "lesMfccTest = build_MFCC(listSons2[-nbTest:], lesMfccTest, dimSonsTest, nbTest)\n",
    "Print('shape :', lesMfccTest.shape)\n",
    "Print(dimSonsTest)\n",
    "\n",
    "\n",
    "# ici on va tester l'apprentissage en faisant varier le nombre de clusters k\n",
    "\n",
    "# apprentissage\n",
    "################################################################################################################\n",
    "\n",
    "test_k_results = {}\n",
    "train_k_results = {}\n",
    "\n",
    "for k in range(2, 50):\n",
    "    monKmeans = KMeans(n_clusters = k) # création de l'objet\n",
    "    monKmeans.fit(lesMfcc) # apprentissage\n",
    "    lesLabels = monKmeans.labels_ # tableau des numéros de \"regroupement\" de toutes nos MFCC\n",
    "    \n",
    "    bofs = build_bof(k, lesLabels, dimSons)\n",
    "        \n",
    "    logisticRegr = LogisticRegression() # création de l'objet de regression logistique\n",
    "\n",
    "    # classes des sons (0 pour classe1 et 1 pour classe2)\n",
    "    groundTruth = [0]*nb + [1]*nb\n",
    "\n",
    "    logisticRegr.fit(bofs, groundTruth) # apprentissage\n",
    "    resTrain = logisticRegr.predict(bofs)\n",
    "    scoreTrain = f1_score(groundTruth, resTrain)\n",
    "    print(f'train score pour k = {k}:', scoreTrain)\n",
    "    train_k_results[k] = scoreTrain\n",
    "\n",
    "\n",
    "\n",
    "    lesLabelsTest = monKmeans.predict(lesMfccTest) # prédiction des partitions pour ces MFCCs\n",
    "    \n",
    "    \n",
    "\n",
    "    bofsTest = build_bof(k, lesLabelsTest, dimSonsTest)\n",
    "    \n",
    "    groundTruthTest = [0]*nbTest + [1]*nbTest\n",
    "    resTest = logisticRegr.predict(bofsTest)\n",
    "    scoreTest = f1_score(groundTruthTest,resTest)\n",
    "    print(f'test score pour k = {k}:', scoreTest)\n",
    "    test_k_results[k] = scoreTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe\n",
    "if verbose:\n",
    "    n = 16000\n",
    "    fe = 8000\n",
    "    te = 1/fe\n",
    "    t = np.linspace(0, n*te, n,endpoint=False)\n",
    "    s = 0.75*np.cos(2*np.pi*280*t) + 0.5*np.cos(2*np.pi*500*t)\n",
    "\n",
    "    fig, graph = plt.subplots(figsize=(15, 5))\n",
    "    graph.plot(list(test_k_results.keys()), list(test_k_results.values()), label = 'Test')\n",
    "    graph.plot(list(train_k_results.keys()), list(train_k_results.values()), label = 'Train')\n",
    "    plt.legend()\n",
    "    graph.set_xlabel('k')\n",
    "    graph.set_ylabel('Taux de validité')\n",
    "    graph.set_title('Pourcentage de validité en fonction de k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k max = 0.8837209302325583\n",
      "file:  ./Sons/Gauche/AM_gauche.wav \tMFCC: (13, 69) \tlen: 35280\n",
      "file:  ./Sons/Gauche/AP_Gauche.wav \tMFCC: (13, 74) \tlen: 37632\n",
      "file:  ./Sons/Gauche/A_Gauche.wav \tMFCC: (13, 65) \tlen: 32928\n",
      "file:  ./Sons/Gauche/Gauche1.wav \tMFCC: (13, 108) \tlen: 55125\n",
      "file:  ./Sons/Gauche/Gauche10.wav \tMFCC: (13, 68) \tlen: 34304\n",
      "file:  ./Sons/Gauche/Gauche11.wav \tMFCC: (13, 164) \tlen: 83456\n",
      "file:  ./Sons/Gauche/Gauche12.wav \tMFCC: (13, 44) \tlen: 22050\n",
      "file:  ./Sons/Gauche/Gauche13.wav \tMFCC: (13, 35) \tlen: 17640\n",
      "file:  ./Sons/Gauche/Gauche14.wav \tMFCC: (13, 44) \tlen: 22051\n",
      "file:  ./Sons/Gauche/Gauche15.wav \tMFCC: (13, 35) \tlen: 17643\n",
      "file:  ./Sons/Droite/AM_droite.wav \tMFCC: (13, 57) \tlen: 29165\n",
      "file:  ./Sons/Droite/AP_Droite.wav \tMFCC: (13, 65) \tlen: 32928\n",
      "file:  ./Sons/Droite/A_Droite.wav \tMFCC: (13, 62) \tlen: 31517\n",
      "file:  ./Sons/Droite/Droite1.wav \tMFCC: (13, 151) \tlen: 77175\n",
      "file:  ./Sons/Droite/Droite10.wav \tMFCC: (13, 86) \tlen: 43520\n",
      "file:  ./Sons/Droite/Droite11.wav \tMFCC: (13, 72) \tlen: 36352\n",
      "file:  ./Sons/Droite/Droite12.wav \tMFCC: (13, 160) \tlen: 81408\n",
      "file:  ./Sons/Droite/Droite13.wav \tMFCC: (13, 160) \tlen: 81408\n",
      "file:  ./Sons/Droite/Droite14.wav \tMFCC: (13, 52) \tlen: 26460\n",
      "file:  ./Sons/Droite/Droite15.wav \tMFCC: (13, 52) \tlen: 26460\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m lesMfcc \u001B[38;5;241m=\u001B[39m build_MFCC(listSons2, lesMfcc, dimSons, nb)\n\u001B[0;32m     10\u001B[0m monKmeans \u001B[38;5;241m=\u001B[39m KMeans(n_clusters \u001B[38;5;241m=\u001B[39m k) \u001B[38;5;66;03m# création de l'objet\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[43mmonKmeans\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlesMfcc\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# apprentissage\u001B[39;00m\n\u001B[0;32m     12\u001B[0m lesLabels \u001B[38;5;241m=\u001B[39m monKmeans\u001B[38;5;241m.\u001B[39mlabels_ \u001B[38;5;66;03m# tableau des numéros de \"regroupement\" de toutes nos MFCC\u001B[39;00m\n\u001B[0;32m     14\u001B[0m bofs \u001B[38;5;241m=\u001B[39m build_bof(k, lesLabels, dimSons)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1179\u001B[0m, in \u001B[0;36mKMeans.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1175\u001B[0m best_inertia, best_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_init):\n\u001B[0;32m   1178\u001B[0m     \u001B[38;5;66;03m# Initialize centers\u001B[39;00m\n\u001B[1;32m-> 1179\u001B[0m     centers_init \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_centroids\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1180\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_squared_norms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[0;32m   1181\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1182\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInitialization complete\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1090\u001B[0m, in \u001B[0;36mKMeans._init_centroids\u001B[1;34m(self, X, x_squared_norms, init, random_state, init_size)\u001B[0m\n\u001B[0;32m   1087\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1089\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(init, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m init \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk-means++\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 1090\u001B[0m     centers, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_kmeans_plusplus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1091\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1092\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1093\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1094\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx_squared_norms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1095\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1096\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(init, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m init \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1097\u001B[0m     seeds \u001B[38;5;241m=\u001B[39m random_state\u001B[38;5;241m.\u001B[39mpermutation(n_samples)[:n_clusters]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:184\u001B[0m, in \u001B[0;36m_kmeans_plusplus\u001B[1;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001B[0m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;124;03m\"\"\"Computational component for initialization of n_clusters by\u001B[39;00m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;124;03mk-means++. Prior validation of data is assumed.\u001B[39;00m\n\u001B[0;32m    151\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;124;03m    given index and center, X[index] = center.\u001B[39;00m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    182\u001B[0m n_samples, n_features \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m--> 184\u001B[0m centers \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_features\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;66;03m# Set the number of local seeding trials if none is given\u001B[39;00m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_local_trials \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;66;03m# This is what Arthur/Vassilvitskii tried, but did not report\u001B[39;00m\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;66;03m# specific results for other than mentioning in the conclusion\u001B[39;00m\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;66;03m# that it helped.\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "k = max(test_k_results.values())\n",
    "print(f\"k max = {k}\")\n",
    "\n",
    "for nb in range(10, 301):\n",
    "    lesMfcc = np.empty(shape = (0, 13), dtype = float) # tableau de tous les MFCC (de tous les sons)\n",
    "    dimSons = []\n",
    "    lesMfcc = build_MFCC(listSons1, lesMfcc, dimSons, nb)\n",
    "    lesMfcc = build_MFCC(listSons2, lesMfcc, dimSons, nb)\n",
    "    \n",
    "    monKmeans = KMeans(n_clusters = k) # création de l'objet\n",
    "    monKmeans.fit(lesMfcc) # apprentissage\n",
    "    lesLabels = monKmeans.labels_ # tableau des numéros de \"regroupement\" de toutes nos MFCC\n",
    "    \n",
    "    bofs = build_bof(k, lesLabels, dimSons)\n",
    "        \n",
    "    logisticRegr = LogisticRegression() # création de l'objet de regression logistique\n",
    "\n",
    "    # classes des sons (0 pour classe1 et 1 pour classe2)\n",
    "    groundTruth = [0]*nb + [1]*nb\n",
    "\n",
    "    logisticRegr.fit(bofs, groundTruth) # apprentissage\n",
    "    resTrain = logisticRegr.predict(bofs)\n",
    "    scoreTrain = f1_score(groundTruth, resTrain)\n",
    "    print(f'train score pour k = {k}:', scoreTrain)\n",
    "    train_k_results[k] = scoreTrain\n",
    "    \n",
    "    \n",
    "\n",
    "    bofsTest = build_bof(k, lesLabelsTest, dimSonsTest)\n",
    "    \n",
    "    groundTruthTest = [0]*nbTest + [1]*nbTest\n",
    "    resTest = logisticRegr.predict(bofsTest)\n",
    "    scoreTest = f1_score(groundTruthTest,resTest)\n",
    "    print(f'test score pour nb = {nb}:', scoreTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}