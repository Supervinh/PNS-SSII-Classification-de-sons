{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification des sons avec différentes valeurs de k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partie des imports\n",
    "################################################################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import librosa\n",
    "import librosa.display\n",
    "import sounddevice as sd\n",
    "import IPython.display as ipd\n",
    "import glob\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print(*args, **kwargs):\n",
    "    '''méthode de print conditionnée par la valeur de la variable verbose'''\n",
    "    global verbose\n",
    "    try:\n",
    "        if verbose:\n",
    "            print(*args, *kwargs)\n",
    "    except NameError:\n",
    "        print(*args, *kwargs)\n",
    "        \n",
    "        \n",
    "def build_bof(k, lesLabels, dimSons):\n",
    "    '''méthode pour construire le Bag Of Features d'un échantillon de sons'''\n",
    "    bofs = np.empty(shape = (0, k), dtype = int) # tableau des BoF\n",
    "    i = 0 # indice pour le parcours de MFCC\n",
    "\n",
    "    for nbS in dimSons: # Parcours des sons\n",
    "        tmpBof = np.array([0]*k) # initialisation du BOF pour le son courant\n",
    "        j = 0\n",
    "        while j < nbS: # pour chaque MFCC de ce son\n",
    "            tmpBof[lesLabels[i]] += 1\n",
    "            j+=1\n",
    "            i+=1\n",
    "        tmpBof = tmpBof/nbS # transformation en pourcentage\n",
    "        copyBof = tmpBof.copy()\n",
    "        bofs = np.append(bofs, [copyBof], 0)\n",
    "    \n",
    "    return bofs\n",
    "\n",
    "\n",
    "def build_MFCC(listSons, lesMfcc, dimSons, nb = 20):\n",
    "    '''méthode pour construite le tableau des MFCC d'un échantillon de sons'''\n",
    "    for s in listSons[:nb]: # on prends les nb premiers sons de la liste 1\n",
    "        sig, rate = librosa.load(s)\n",
    "        mfcc_feat = librosa.feature.mfcc(sig,rate,n_mfcc=13) # on calcule les MFCC du son\n",
    "\n",
    "        Print('file: ', '/'.join(s.split('\\\\')[-2:]), '\\tMFCC:', mfcc_feat.shape, '\\tlen:', len(sig))\n",
    "\n",
    "        lesMfcc = np.append(lesMfcc, mfcc_feat.transpose(), axis = 0) # on ajoute les MFCC du son à notre array\n",
    "        dimSons.append(mfcc_feat.shape[1]) # et on \"déclare\" le nombre de MFCC du son\n",
    "    return lesMfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partie d'initialisation des fichiers sons\n",
    "################################################################################################################\n",
    "\n",
    "basedir=r'C:\\Users\\Romain\\Documents\\SSII\\TP noté'\n",
    "class1 = 'four'\n",
    "class2 = 'five'\n",
    "\n",
    "listSons1 = glob.glob(basedir + '\\\\' + class1 + r'\\*.wav')\n",
    "listSons2 = glob.glob(basedir + '\\\\' + class2 + r'\\*.wav')\n",
    "\n",
    "Print(f'Classe 1: {len(listSons1)} sons.'.format())\n",
    "Print(f'Classe 2: {len(listSons2)} sons.'.format())\n",
    "\n",
    "\n",
    "# partie construction du vecteur de tous les MFCC\n",
    "################################################################################################################\n",
    "\n",
    "nb = 20 # nombre de sons dans l'échantillon\n",
    "lesMfcc = np.empty(shape = (0, 13), dtype = float) # tableau de tous les MFCC (de tous les sons)\n",
    "dimSons = []\n",
    "lesMfcc = build_MFCC(listSons1, lesMfcc, dimSons, nb)\n",
    "Print()\n",
    "lesMfcc = build_MFCC(listSons2, lesMfcc, dimSons, nb)\n",
    "Print('\\nNombre total de MFCC:', lesMfcc.shape)\n",
    "Print('Nombre de MFCC dans l\\'ordre des sons:', dimSons)\n",
    "\n",
    "\n",
    "nbTest=20\n",
    "lesMfccTest = np.empty(shape=(0, 13), dtype=float)\n",
    "dimSonsTest = []\n",
    "# on va prendre les nb derniers sons\n",
    "lesMfccTest = build_MFCC(listSons1[-nbTest:], lesMfccTest, dimSonsTest, nbTest)\n",
    "lesMfccTest = build_MFCC(listSons2[-nbTest:], lesMfccTest, dimSonsTest, nbTest)\n",
    "Print('shape :', lesMfccTest.shape)\n",
    "Print(dimSonsTest)\n",
    "\n",
    "\n",
    "# ici on va tester l'apprentissage en faisant varier le nombre de clusters k\n",
    "\n",
    "# apprentissage\n",
    "################################################################################################################\n",
    "\n",
    "test_k_results = {}\n",
    "train_k_results = {}\n",
    "\n",
    "for k in range(2, 120):\n",
    "    monKmeans = KMeans(n_clusters = k) # création de l'objet\n",
    "    monKmeans.fit(lesMfcc) # apprentissage\n",
    "    lesLabels = monKmeans.labels_ # tableau des numéros de \"regroupement\" de toutes nos MFCC\n",
    "    \n",
    "    bofs = build_bof(k, lesLabels, dimSons)\n",
    "        \n",
    "    logisticRegr = LogisticRegression() # création de l'objet de regression logistique\n",
    "\n",
    "    # classes des sons (0 pour classe1 et 1 pour classe2)\n",
    "    groundTruth = [0]*nb + [1]*nb\n",
    "\n",
    "    logisticRegr.fit(bofs, groundTruth) # apprentissage\n",
    "    resTrain = logisticRegr.predict(bofs)\n",
    "    scoreTrain = f1_score(groundTruth, resTrain)\n",
    "    print(f'train score pour k = {k}:', scoreTrain)\n",
    "    train_k_results[k] = scoreTrain\n",
    "\n",
    "\n",
    "\n",
    "    lesLabelsTest = monKmeans.predict(lesMfccTest) # prédiction des partitions pour ces MFCCs\n",
    "    \n",
    "    \n",
    "\n",
    "    bofsTest = build_bof(k, lesLabelsTest, dimSonsTest)\n",
    "    \n",
    "    groundTruthTest = [0]*nbTest + [1]*nbTest\n",
    "    resTest = logisticRegr.predict(bofsTest)\n",
    "    scoreTest = f1_score(groundTruthTest,resTest)\n",
    "    print(f'test score pour k = {k}:', scoreTest)\n",
    "    test_k_results[k] = scoreTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe\n",
    "if verbose:\n",
    "    n = 16000\n",
    "    fe = 8000\n",
    "    te = 1/fe\n",
    "    t = np.linspace(0, n*te, n,endpoint=False)\n",
    "    s = 0.75*np.cos(2*np.pi*280*t) + 0.5*np.cos(2*np.pi*500*t)\n",
    "\n",
    "    fig, graph = plt.subplots(figsize=(15, 5))\n",
    "    graph.plot(list(test_k_results.keys()), list(test_k_results.values()), label = 'Test')\n",
    "    graph.plot(list(train_k_results.keys()), list(train_k_results.values()), label = 'Train')\n",
    "    plt.legend()\n",
    "    graph.set_xlabel('k')\n",
    "    graph.set_ylabel('Taux de validité')\n",
    "    graph.set_title('Pourcentage de validité en fonction de k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = max(test_k_results.values())\n",
    "print(f\"k max = {k}\")\n",
    "\n",
    "for nb in range(10, 301):\n",
    "    lesMfcc = np.empty(shape = (0, 13), dtype = float) # tableau de tous les MFCC (de tous les sons)\n",
    "    dimSons = []\n",
    "    lesMfcc = build_MFCC(listSons1, lesMfcc, dimSons, nb)\n",
    "    lesMfcc = build_MFCC(listSons2, lesMfcc, dimSons, nb)\n",
    "    \n",
    "    monKmeans = KMeans(n_clusters = k) # création de l'objet\n",
    "    monKmeans.fit(lesMfcc) # apprentissage\n",
    "    lesLabels = monKmeans.labels_ # tableau des numéros de \"regroupement\" de toutes nos MFCC\n",
    "    \n",
    "    bofs = build_bof(k, lesLabels, dimSons)\n",
    "        \n",
    "    logisticRegr = LogisticRegression() # création de l'objet de regression logistique\n",
    "\n",
    "    # classes des sons (0 pour classe1 et 1 pour classe2)\n",
    "    groundTruth = [0]*nb + [1]*nb\n",
    "\n",
    "    logisticRegr.fit(bofs, groundTruth) # apprentissage\n",
    "    resTrain = logisticRegr.predict(bofs)\n",
    "    scoreTrain = f1_score(groundTruth, resTrain)\n",
    "    print(f'train score pour k = {k}:', scoreTrain)\n",
    "    train_k_results[k] = scoreTrain\n",
    "    \n",
    "    \n",
    "\n",
    "    bofsTest = build_bof(k, lesLabelsTest, dimSonsTest)\n",
    "    \n",
    "    groundTruthTest = [0]*nbTest + [1]*nbTest\n",
    "    resTest = logisticRegr.predict(bofsTest)\n",
    "    scoreTest = f1_score(groundTruthTest,resTest)\n",
    "    print(f'test score pour nb = {nb}:', scoreTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
